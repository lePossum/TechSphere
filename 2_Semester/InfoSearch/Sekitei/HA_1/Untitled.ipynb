{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import sys\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "import urllib\n",
    "import ef\n",
    "# you may add imports if needed (and if they are installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"http://ru.wikipedia.org/?oldid=11298863\"\n",
    "u = \"http://lenta.ru/news/2013/12/30/count/?TB_iframe=true&height=650&keepThis=true&width=850\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(INPUT_FILE_1, INPUT_FILE_2, OUTPUT_FILE):\n",
    "    examined = open(INPUT_FILE_1, \"r\")\n",
    "    general = open(INPUT_FILE_2, \"r\")\n",
    "    result = open(OUTPUT_FILE, \"w\")\n",
    "\n",
    "    sample_size = 1000\n",
    "    min_count = 100\n",
    "\n",
    "    examined_lines = random.sample(examined.read().split('\\n'), sample_size)\n",
    "    general_lines = random.sample(general.read().split('\\n'), sample_size)\n",
    "\n",
    "    features = extract_features_from_list(examined_lines, general_lines)\n",
    "\n",
    "    for key, value in features:\n",
    "        if value < min_count:\n",
    "            break\n",
    "        result.write(key + '\\t' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_files = [\"data/urls.lenta.general\", \"data/urls.wikipedia.general\", \"data/urls.zr.general\"]\n",
    "examined_files = [\"data/urls.lenta.examined\", \"data/urls.wikipedia.examined\", \"data/urls.zr.examined\"]\n",
    "res_files = [\"results/lenta.res\", \"results/wikipedia.res\", \"results/zr.res\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_list(QLINK_LIST, UNKNOWN_URLS_LIST):\n",
    "    lines = []\n",
    "    features = Counter()\n",
    "\n",
    "    examined_lines = QLINK_LIST\n",
    "    general_lines = UNKNOWN_URLS_LIST\n",
    "    lines.extend(examined_lines)\n",
    "    lines.extend(general_lines)\n",
    "\n",
    "    for line in lines:\n",
    "        if line.find('\\n') != -1:\n",
    "            line = line[0:len(line) - 1]\n",
    "        features_from_url = extract_features_from_url(line)\n",
    "        for feature in features_from_url:\n",
    "            features[feature] += 1\n",
    "\n",
    "    features = features.most_common()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_url(url):\n",
    "    features = []\n",
    "\n",
    "    # feature 1\n",
    "    features.append(\"segments:\" + str(count_segments(url)))\n",
    "    # feature 2\n",
    "    for name in extract_param_names(url):\n",
    "        features.append(\"param_name:\" + name)\n",
    "    # feature 3\n",
    "    for param in extract_params(url):\n",
    "        if len(param) == 1:\n",
    "            param.append(\"\")\n",
    "        features.append(\"param:\" + param[0] + \"=\" + param[1])\n",
    "    # features 4a - 4f\n",
    "    segments = extract_segments(url)\n",
    "    for pos, segment in enumerate(segments):\n",
    "        segment_decoded = urllib.parse.unquote(segment)\n",
    "        regex_res = re.findall(\"[^\\\\d]+\\\\d+[^\\\\d]+$\", segment_decoded)\n",
    "        # feature 4a\n",
    "        features.append(\"segment_name_\" + str(pos) + \":\" + segment)\n",
    "        # feature 4b\n",
    "        if segment.isdigit():\n",
    "            features.append(\"segment_[0-9]_\" + str(pos) + \":1\")\n",
    "        # feature 4c\n",
    "        if len(regex_res) == 1 and regex_res[0] == segment_decoded:\n",
    "            features.append(\"segment_substr[0-9]_\" + str(pos) + \":1\")\n",
    "        # feature 4d\n",
    "        extension = get_extension(segment)\n",
    "        if len(extension) != 0:\n",
    "            features.append(\"segment_ext_\" + str(pos) + \":\" + extension)\n",
    "        # feature 4e\n",
    "        if len(regex_res) == 1 and regex_res[0] == segment_decoded and len(extension) != 0:\n",
    "            features.append(\"segment_ext_substr[0-9]_\" + str(pos) + \":\" + extension)\n",
    "        # feature 4f\n",
    "        features.append(\"segment_len_\" + str(pos) + \":\" + str(len(segment)))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ef.extract_features(general_files[0], examined_files[0], res_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ef.extract_features_from_url(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segments:6',\n",
       " 'param_name:TB_iframe',\n",
       " 'param_name:height',\n",
       " 'param_name:keepThis',\n",
       " 'param_name:width',\n",
       " 'param:TB_iframe=true',\n",
       " 'param:height=650',\n",
       " 'param:keepThis=true',\n",
       " 'param:width=85',\n",
       " 'segment_name_0:news',\n",
       " 'segment_len_0:4',\n",
       " 'segment_name_1:2013',\n",
       " 'segment_[0-9]_1:1',\n",
       " 'segment_len_1:4',\n",
       " 'segment_name_2:12',\n",
       " 'segment_[0-9]_2:1',\n",
       " 'segment_len_2:2',\n",
       " 'segment_name_3:30',\n",
       " 'segment_[0-9]_3:1',\n",
       " 'segment_len_3:2',\n",
       " 'segment_name_4:count',\n",
       " 'segment_len_4:5']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ef.extract_features_from_url(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segments:6',\n",
       " 'param_name:TB_iframe',\n",
       " 'param_name:height',\n",
       " 'param_name:keepThis',\n",
       " 'param_name:width',\n",
       " 'param:TB_iframe=true',\n",
       " 'param:height=650',\n",
       " 'param:keepThis=true',\n",
       " 'param:width=85',\n",
       " 'segment_name_0:news',\n",
       " 'segment_len_0:4',\n",
       " 'segment_name_1:2013',\n",
       " 'segment_[0-9]_1:1',\n",
       " 'segment_len_1:4',\n",
       " 'segment_name_2:12',\n",
       " 'segment_[0-9]_2:1',\n",
       " 'segment_len_2:2',\n",
       " 'segment_name_3:30',\n",
       " 'segment_[0-9]_3:1',\n",
       " 'segment_len_3:2',\n",
       " 'segment_name_4:count',\n",
       " 'segment_len_4:5']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
